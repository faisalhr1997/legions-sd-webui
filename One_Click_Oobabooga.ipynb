{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "mount_file_id": "1glB99Snng4JmxKiFjTisM0lFPYS5XvvZ",
      "authorship_tag": "ABX9TyOqT5/fhqZzZrUvvWR0Nate",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x-legion/legions-sd-notebooks/blob/main/One_Click_Oobabooga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown üéµ`Press play on the music player that will appear below:`\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "R0eIeVNk4taP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.1 Install and Run WebUI { display-mode: \"form\" }\n",
        "!pip install requests_file pyrfc6266\n",
        "\n",
        "import shutil\n",
        "import os, re, csv, requests, pyrfc6266\n",
        "from IPython.display import clear_output\n",
        "!apt -y update -qq\n",
        "!apt install aria2\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "#@markdown ‚ö†Ô∏è`Google drive is limited to 15GB storage only`\n",
        "everything_on_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown `Insert necessary ` [Basic Settings](https://github.com/oobabooga/text-generation-webui/blob/main/README.md#basic-settings) ` in launch_arguments`\n",
        "launch_arguments = \"--share --chat --settings settings-colab-template.json\" #@param [\"--share --chat --settings settings-colab-template.json\"] {allow-input: true}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #**Download Models**\n",
        "#@markdown `Insert any` [HuggingFace](https://huggingface.co/TheBloke) `model repo in <Organization>/<model> format`\n",
        "hf_model_download = \"\" # @param [\"TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ\", \"TheBloke/WizardCoder-15B-1.0-GPTQ\", \"TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ\", \"TheBloke/Pygmalion-13B-SuperHOT-8K-GPTQTheBloke/Pygmalion-13B-SuperHOT-8K-GPTQ\", \"TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ\", \"\"] {allow-input: true}\n",
        "# @markdown `Insert any` [HuggingFace](https://huggingface.co/TheBloke) `model links for download. (Input multiple links separated by comma)`\n",
        "download_links = \"\" # @param [\"\"] {allow-input: true}\n",
        "\n",
        "\n",
        "# everything on google drive\n",
        "if everything_on_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd /content/drive/MyDrive\n",
        "  repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "  if os.path.exists(repo_dir):\n",
        "    %cd {repo_dir}\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui.git\n",
        "\n",
        "else:\n",
        "  %cd /content\n",
        "  repo_dir = '/content/text-generation-webui'\n",
        "  if os.path.exists(repo_dir):\n",
        "    %cd {repo_dir}\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui.git\n",
        "\n",
        "\n",
        "%cd {repo_dir}\n",
        "model_dir = f\"{repo_dir}/models\"\n",
        "\n",
        "# hf model download\n",
        "!python download-model.py {hf_model_download}\n",
        "\n",
        "#downloader\n",
        "%cd {repo_dir}\n",
        "links = list(csv.reader([download_links]))[0]\n",
        "session = requests.session()\n",
        "for link in links:\n",
        "  try:\n",
        "    response = session.get(link, stream=True)\n",
        "    file_name = pyrfc6266.requests_response_to_filename(response)\n",
        "    print(f\"Downloading {file_name} to {model_dir}\")\n",
        "    !aria2c -x 16 -s 16 -d {model_dir} {link} -o {file_name}\n",
        "    clear_output()\n",
        "  except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# install requirements\n",
        "%cd {repo_dir}\n",
        "!wget https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json -O settings-colab-template.json\n",
        "!pip install -r requirements.txt\n",
        "# !pip install -r /extensions/api/requirements.txt\n",
        "# !pip install -r /extensions/google_translate/requirements.txt\n",
        "# !pip install -r /extensions/ngrok/requirements.txt\n",
        "# !pip install -r /extensions/elevenlabs_tts/requirements.txt\n",
        "# !pip install -r /extensions/openai/requirements.txt\n",
        "# !pip install -r /extensions/silero_tts/requirements.txt\n",
        "# !pip install -r /extensions/superbooga/requirements.txt\n",
        "# !pip install -r /extensions/whisper_stt/requirements.txt\n",
        "\n",
        "!pip uninstall -y llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir\n",
        "clear_output(wait=True)\n",
        "\n",
        "# list models\n",
        "print(\"Models Directory\")\n",
        "print(os.listdir(model_dir))\n",
        "\n",
        "# run webui\n",
        "!python server.py {launch_arguments}"
      ],
      "metadata": {
        "id": "5bazisNevrfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Run WebUI `in case of OOM` { display-mode: \"form\" }\n",
        "\n",
        "!python server.py {launch_arguments}\n"
      ],
      "metadata": {
        "id": "oF-T6SIjTeG0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}